{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Project - Artist Classifaction Using MP3 song files.\n",
    "### Project Members - Dhrumil Shah & Sarthak Tandon\n",
    "\n",
    "#### The aim of this project was to use song files in mp3 format from 20 artists and to make Neural Network architectures to identify the artists using the song files.  \n",
    "\n",
    "### Dataset Link : https://www.kaggle.com/dhrumil140396/mp3s32k "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility\n",
    "\n",
    "### This code block has the following purpose:\n",
    "#### 1)  transform - Read the mp3 files from the source folder and convert them to melspectrograms, followed by log tranformation and finally saving each file in pickle format\n",
    "#### 2)  load_album - Load the transformed files and split them to training, validation and testing set based on the albums from artists. For each artist, songs from one album will go to  testing set, one to validation set and the rest to training set.\n",
    "#### 3) load_songs - Load the transformed files and does simple training, validation and testing split. The split is stratifies to ensure that all the artists are present in all the sets.\n",
    "#### 4) slice_songs - Takes each song from the training, validation and testing set and slices them to smaller samples based on the number of frames provides. \n",
    "#### 5) encode_labels - Takes the labels from training, validation and testing set and perfroms label encoding, followed by onehot encoding.\n",
    "#### 6) plot_spectrogram - Plots a spectrogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "\n",
    "import os\n",
    "import random\n",
    "import librosa as lib\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    " \n",
    "def transform(data_path,dataset_path,sampling_rate = 16000):\n",
    "    os.makedirs(dataset_path, exist_ok=True)\n",
    "    start = datetime.now() # Timer to check display time taken to process all the files\n",
    "    artists = [artist for artist in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, artist))] #store the lists of artists \n",
    "    \n",
    "    for artist in artists:\n",
    "        print(\"Accessing Artist: {}\".format(artist))\n",
    "        artist_path = os.path.join(data_path, artist)\n",
    "        albums = os.listdir(artist_path)\n",
    "\n",
    "        for album in albums:\n",
    "            print(\"-- Album: {}\".format(album))\n",
    "            album_path = os.path.join(artist_path, album)\n",
    "            songs = os.listdir(album_path)\n",
    "\n",
    "            for song in songs:\n",
    "                print(\"---- Song: {}\".format(song))\n",
    "                song_path = os.path.join(album_path,song)\n",
    "                y,sr = lib.load(song_path, sr=sampling_rate)\n",
    "                \n",
    "                S = lib.feature.melspectrogram(y,sr=sr)\n",
    "                S = lib.power_to_db(S) #Transforming the songs to Spectrograms followed by log transformation\n",
    "                    \n",
    "                file = artist+\"--\"+album+\"--\"+song\n",
    "                data = (S,artist,song)\n",
    "                \n",
    "                with open(os.path.join(dataset_path,file),'wb') as file_path:\n",
    "                    pk.dump(data,file_path) #Creates the pickle file to store in the destination path provided\n",
    "\n",
    "    print(\"Time taken: {}\".format(datetime.now()-start))\n",
    "\n",
    " \n",
    "\n",
    "def load_album(data_path,dataset_path,random_state = 1234):\n",
    "    random.seed(random_state)\n",
    "    songs =  os.listdir(dataset_path)\n",
    "    artists = [artist for artist in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, artist))]\n",
    "    train, test, val =[], [], [] #Creating 3 lists to store training, testing and validation set.\n",
    "\n",
    "    for artist in artists:\n",
    "        artist_path = os.path.join(data_path, artist)\n",
    "        albums = os.listdir(artist_path)\n",
    "        random.shuffle(albums) # Shuffle the list of artists\n",
    "        test.append(artist + \"--\" + albums.pop(0)) #send one album to the test list\n",
    "        val.append(artist + \"--\" + albums.pop(0)) #send one album to the validation list\n",
    "        train = train + [artist + \"--\" + album for album in albums] #send rest to the training list\n",
    "\n",
    "    #Creating 3 sets of lists to store the songs data, the corresponding artists and song name \n",
    "    X_train, y_train, s_train = [], [], []\n",
    "    X_val, y_val, s_val = [], [], []\n",
    "    X_test, y_test, s_test = [], [], []\n",
    "\n",
    "   \n",
    "\n",
    "    for song in songs:\n",
    "        with open(os.path.join(dataset_path,song),'rb') as file_path:\n",
    "            load = pk.load(file_path) #Load each song file from the dataset path\n",
    "        artist, album, song_name = song.split(\"--\")\n",
    "        artist_album = artist + \"--\" + album\n",
    "\n",
    "\n",
    "        if artist_album in train:\n",
    "            X_train.append(load[0]) # Load the song file\n",
    "            y_train.append(load[1]) # Load the artists name\n",
    "            s_train.append(load[2]) # Laod the song name \n",
    "        \n",
    "        elif artist_album in val:\n",
    "            X_val.append(load[0])\n",
    "            y_val.append(load[1])\n",
    "            s_val.append(load[2])\n",
    "\n",
    "        elif artist_album in test:\n",
    "            X_test.append(load[0])\n",
    "            y_test.append(load[1])\n",
    "            s_test.append(load[2])\n",
    "\n",
    "    return X_train, y_train, s_train, X_val, y_val, s_val, X_test, y_test, s_test\n",
    "\n",
    "   \n",
    "\n",
    "def load_songs(data_path,dataset_path,val_size,test_size,random_state = 1234):\n",
    "    songs =  os.listdir(dataset_path)\n",
    "    X, Y, s =[], [], [] #Creating 3 lists to store the songs data, the corresponding artists and song name \n",
    "\n",
    "    for song in songs:\n",
    "        with open(os.path.join(dataset_path,song),'rb') as file_path:\n",
    "            load = pk.load(file_path)\n",
    "        X.append(load[0]) # Load the song file\n",
    "        Y.append(load[1]) # Load the artists name\n",
    "        s.append(load[2]) # Laod the song name \n",
    "\n",
    "    #split the dataset to training and testing    \n",
    "    X_train, X_test, Y_train, Y_test, s_train, s_test = train_test_split(X, Y, s, test_size=test_size, stratify=Y, shuffle=True,random_state=random_state)\n",
    "    #split the dataset to training and validation  \n",
    "    X_train, X_val, Y_train, Y_val, s_train, s_val = train_test_split(X_train, Y_train, s_train, test_size=val_size, shuffle=True, stratify=Y_train, random_state=random_state)\n",
    "\n",
    "    return X_train, Y_train, s_train, X_val, Y_val, s_val, X_test, Y_test, s_test\n",
    "\n",
    " \n",
    "\n",
    "def slice_song(X,y,S, slice_len):\n",
    "    spectrograms, artists, songs = [], [], [] #Creating 3 lists to store the songs data, the corresponding artists and song name \n",
    "    \n",
    "    for i, spectrogram in enumerate(X):\n",
    "        slices = spectrogram.shape[1]//slice_len #Calculate the number of slices in each song\n",
    "        \n",
    "        for j in range(slices-1):\n",
    "            spectrograms.append(spectrogram[:,(slice_len*j):(slice_len*(j+1))]) #store the song slices in the list\n",
    "            artists.append(y[i]) #store the corresponding artists\n",
    "            songs.append(S[i]) #store the corresponding song\n",
    "\n",
    "    return np.array(spectrograms), np.array(artists), np.array(songs)\n",
    "\n",
    "   \n",
    "def encode(y, label=None, onehot=None):\n",
    "    y_len = len(y)\n",
    "    \n",
    "    #Perfrom Label encoding on the labels. If a Label encoder is not provided, create a new one.\n",
    "    if not label:\n",
    "        label = preprocessing.LabelEncoder()\n",
    "    y_label = label.fit_transform(y).reshape(y_len,1)\n",
    "    \n",
    "    #Perfrom OneHot encoding on the labels. If a OneHot encoder is not provided, create a new one.\n",
    "    if not onehot:\n",
    "        onehot = preprocessing.OneHotEncoder()\n",
    "    y_onehot = onehot.fit_transform(y_label).toarray()\n",
    "\n",
    "    return y_onehot, label, onehot\n",
    "\n",
    "def plot_spectrogram(S):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    lib.display.specshow(S, sr=16000, x_axis='time', y_axis='mel')\n",
    "    plt.title('mel power spectrogram')\n",
    "    plt.colorbar(format='%+02.0f dB')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer\n",
    "\n",
    "### This code block has the following purpose:\n",
    "#### 1) load_data: creates dataloader class for the dataset corresponding to the batch size provided. It also adjusts the shape of the dataset to be compatible with the models. It also transfroms the dataset if any transformation is provided.\n",
    "#### 2) train_predict: trains the model provided based on the epochs and learning rate provided. Returns the training loss, validation loss, training F1 scores, validation F1 scores, time and the final model.\n",
    "#### 3) test_predict: runs the model on the testing dataset and returns the F1 score\n",
    "#### 4) plot_trn_val_loss: plot the loss between training and validation\n",
    "#### 5) plot_trn_val_f1: plot the F1 scores between training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn  as nn\n",
    "from torch.autograd import Variable \n",
    "import matplotlib.pyplot as plt\n",
    "from ignite.metrics import Accuracy, Precision, Recall, Fbeta\n",
    "\n",
    "def load_data(X,y,batch_size,transform=None):\n",
    "    data =[]\n",
    "    for i in range(len(X)):\n",
    "        if transform:\n",
    "            x = transfrom(X[i]) # Performs tensor transfrom if provided\n",
    "        else:\n",
    "            x = np.swapaxes(np.swapaxes(X[i],0,2),1,2) # Reshapes the data\n",
    "        data.append([x, y[i]])\n",
    "    dataloader = torch.utils.data.DataLoader(data, shuffle=True, batch_size=batch_size) #Creates a dataloader\n",
    "    return dataloader\n",
    "\n",
    "def train_predict(dataloader_train,dataloader_val,model,epochs,learning_rate,use_cuda):\n",
    "    \n",
    "    #Creates timer to calculate model runtime\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    \n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    model = model.train() #sets model to staining mode\n",
    "    \n",
    "    start.record()\n",
    "    train_loss_list=[]\n",
    "    val_loss_list=[]\n",
    "    train_f1=[]\n",
    "    val_f1=[]\n",
    "    loss_fn = nn.CrossEntropyLoss() # creating loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # creating optimizer\n",
    "    \n",
    "    #Creating evaluation metrics for Training set\n",
    "    precision_train = Precision()\n",
    "    accuracy_train = Accuracy()\n",
    "    recall_train = Recall()\n",
    "    f1_train = Fbeta(beta=1.0, average=True, precision=precision_train, recall=recall_train)\n",
    "    \n",
    "    #Creating evaluation metrics for Validation set\n",
    "    precision_val = Precision()\n",
    "    recall_val = Recall()\n",
    "    f1_val= Fbeta(beta=1.0, average=True, precision=precision_val, recall=recall_val)\n",
    "    accuracy_val = Accuracy()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #Reset the metrics for each epoch run\n",
    "        precision_train.reset()\n",
    "        accuracy_train.reset()\n",
    "        recall_train.reset()\n",
    "        f1_train.reset()\n",
    "        \n",
    "        print(\"Epoch: {}\".format(epoch+1))\n",
    "        \n",
    "        for i,(img, label) in enumerate(dataloader_train):\n",
    "            img, label = Variable(img),Variable(label)\n",
    "            if use_cuda:\n",
    "                img = img.cuda()\n",
    "                label = label.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            pred = model.forward(img) #make prediction with the model\n",
    "            _,my_label = torch.max(label, dim=1) #get the best result \n",
    "            loss = loss_fn(pred,my_label) #Calculate Loss\n",
    "            if i == len(dataloader_train)-1:\n",
    "                train_loss_list.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Update the metrics after each batch run\n",
    "            precision_train.update((pred, my_label))\n",
    "            recall_train.update((pred, my_label))\n",
    "            f1_train.update((pred, my_label))\n",
    "            accuracy_train.update((pred, my_label))\n",
    "        \n",
    "        #Print the Metric after each epoch run\n",
    "        train_f1.append(f1_train.compute()*100)\n",
    "        print(\"\\tTrain loss: {:0.2f}\".format(train_loss_list[-1]))\n",
    "        print(\"\\tTrain Accuracy: {:0.2f}%\".format(accuracy_train.compute()*100))\n",
    "        print(\"\\tTrain Precision: {:0.2f}%\".format(precision_train.compute().mean()*100))\n",
    "        print(\"\\tTrain Recall: {:0.2f}%\".format(recall_train.compute().mean()*100))\n",
    "        print(\"\\tTrain F1 Score: {:0.2f}%\".format(train_f1[-1]))\n",
    "        \n",
    "        \n",
    "        precision_val.reset()\n",
    "        accuracy_val.reset()\n",
    "        recall_val.reset()\n",
    "        f1_val.reset()\n",
    "        \n",
    "        #Make prediction on the validation set using the updated model\n",
    "        with torch.no_grad():\n",
    "            for i,(img, label) in enumerate(dataloader_val):\n",
    "                img, label = Variable(img),Variable(label)\n",
    "                if use_cuda:\n",
    "                    img = img.cuda()\n",
    "                    label = label.cuda()\n",
    "                pred = model(img)\n",
    "                _,my_label = torch.max(label, dim=1)\n",
    "                loss = loss_fn(pred,my_label)\n",
    "                if i == len(dataloader_val)-1:\n",
    "                    val_loss_list.append(loss.item())\n",
    "                \n",
    "                precision_val.update((pred, my_label))\n",
    "                recall_val.update((pred, my_label))\n",
    "                f1_val.update((pred, my_label))\n",
    "                accuracy_val.update((pred, my_label))\n",
    "        \n",
    "        val_f1.append(f1_val.compute()*100)\n",
    "        print(\"\\n\\tVal loss: {:0.2f}\".format(val_loss_list[-1]))\n",
    "        print(\"\\tVal Accuracy: {:0.2f}%\".format(accuracy_val.compute()*100))\n",
    "        print(\"\\tVal Precision: {:0.2f}%\".format(precision_val.compute().mean()*100))\n",
    "        print(\"\\tVal Recall: {:0.2f}%\".format(recall_val.compute().mean()*100))\n",
    "        print(\"\\tVal F1 Score: {:0.2f}%\".format(val_f1[-1]))\n",
    "        \n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    time = start.elapsed_time(end)\n",
    "    return (train_loss_list,val_loss_list,train_f1,val_f1,time,model)\n",
    "\n",
    "def test_predict(model,dataloader_test,use_cuda):\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    #Creating evaluation metrics for testing set\n",
    "    precision = Precision()\n",
    "    recall = Recall()\n",
    "    f1 = Fbeta(beta=1.0, average=True, precision=precision, recall=recall)\n",
    "    \n",
    "    for i,(img, label) in enumerate(dataloader_test):\n",
    "        img, label = Variable(img),Variable(label)\n",
    "        if use_cuda:\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "            pred = model(img)\n",
    "            _,my_label = torch.max(label, dim=1)\n",
    "            precision.update((pred, my_label))\n",
    "            recall.update((pred, my_label))\n",
    "            f1.update((pred, my_label))\n",
    "            \n",
    "    precision.compute()\n",
    "    recall.compute()\n",
    "    print(\"\\tF1 Score: {:0.2f}%\".format(f1.compute()*100))\n",
    "\n",
    "def plot_trn_val_loss(train,val):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(train,label=\"Training Dataset\")\n",
    "    plt.plot(val,label=\"Validation Dataset\")\n",
    "    plt.xlabel(\"Number of epochs\")\n",
    "    plt.ylabel(\"Cross Entropy Loss\")\n",
    "    plt.xticks(range(0,len(train),2))\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_trn_val_f1(train,val):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(train,label=\"Training Dataset\")\n",
    "    plt.plot(val,label=\"Validation Dataset\")\n",
    "    plt.xlabel(\"Number of epochs\")\n",
    "    plt.ylabel(\"F1 score\")\n",
    "    plt.xticks(range(0,len(train),2))\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 \n",
    "#### Model with Inception Block\n",
    "For the task of the detecting artist from Mel-spectrogram, we have developed a model which uses **inception blocks, convolution blocks, and GRU** as a basic block.\n",
    "1. Since Mel-spectogram is a time vs Mel image it makes sense to use a convolution block.<br>\n",
    "1. One main idea behind using inception block was to detect **macro and micro-level features** in the image because <br> inception block uses different size of kernels in order to detect the feature out image - (1*1),(3,3) ,(5,5) and (3,3) max pooling, and merges the output of all these filters together. <br>\n",
    "1. Since mel-spectrogram is a mel-time based image we are using 2 layers **stacked-GRU** in order to detect the **feature based on time-based changes**. <br>\n",
    "1. At last output of the GRU is passed through a linear dense layer with output size = number of total artists. We <br> are not calculating the SoftMax probability because it's taken care of by the CrossEntropyLoss we are using while training the model. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn  as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,**kwargs):\n",
    "        super(conv_block,self).__init__()\n",
    "        self.elu = nn.ELU()\n",
    "        self.conv = nn.Conv2d(in_channels,out_channels,**kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.elu(self.batchnorm(self.conv(x)))\n",
    "    \n",
    "class Inception_Block(nn.Module):\n",
    "    def __init__(self,input_channels,out_1x1,reduction_3x3,out_3x3,reduction_5x5,out_5x5,out_1x1pool):\n",
    "        super(Inception_Block,self).__init__()\n",
    "        self.branch1 = conv_block(input_channels,out_1x1,kernel_size=(1,1))\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "                           conv_block(input_channels,reduction_3x3,kernel_size=(1,1)),\n",
    "                           conv_block(reduction_3x3,out_3x3,kernel_size=(3,3),padding=(1,1)),)\n",
    "        self.branch3 = nn.Sequential(\n",
    "                        conv_block(input_channels,reduction_5x5,kernel_size=(1,1)),\n",
    "                        conv_block(reduction_5x5,out_5x5,kernel_size=(5,5),padding=(2,2)),)\n",
    "        self.branch4 = nn.Sequential(\n",
    "                        nn.AvgPool2d(kernel_size=(3,3),stride=(1,1),padding=(1,1)),\n",
    "                        conv_block(input_channels,out_1x1pool,kernel_size=(1,1)))\n",
    "    def forward(self,x):\n",
    "        return torch.cat(\n",
    "            [self.branch1(x),self.branch2(x),self.branch3(x),self.branch4(x)],1)\n",
    "\n",
    "class MusicArtistClassificationModel(nn.Module):\n",
    "    def __init__(self,input_channels,total_artists,use_cuda):\n",
    "        super(MusicArtistClassificationModel,self).__init__()  \n",
    "        \n",
    "        self.batchnorm0 =  nn.BatchNorm2d(input_channels)\n",
    "        \n",
    "        self.layer1 = conv_block(input_channels,3,kernel_size=(3,3),padding=(1,1))\n",
    "        self.batchnorm1 = nn.BatchNorm2d(3)\n",
    "        self.maxpool1 = nn.AvgPool2d(kernel_size=(3,3),stride=2,padding=1)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.layer2 = Inception_Block(3,64,96,128,16,32,32)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(256)\n",
    "        self.maxpool2 = nn.AvgPool2d(kernel_size=(3,3),stride=2,padding=1)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.layer3 = conv_block(256,32,kernel_size=(3,3),padding=(1,1))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(32)\n",
    "        self.maxpool3 = nn.AvgPool2d(kernel_size=(3,3),stride=2,padding=1)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=512, \n",
    "            hidden_size=32, \n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.3)\n",
    "        self.linear = nn.Linear(32,total_artists)\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.batchnorm0(x)\n",
    "        x = self.maxpool1(self.batchnorm1(F.elu(self.layer1(x))))\n",
    "        x = self.maxpool2(self.batchnorm2(F.elu(self.layer2(x))))\n",
    "        x = self.maxpool3(self.batchnorm3(F.elu(self.layer3(x))))\n",
    "        # input format is (B,C,F,T) . For RNN we need input form (B,T,C*F) . where channel and frequency \n",
    "        # dimensions are considered as a feature at any given time.\n",
    "        batch_size, channel,freq, timesteps = x.size()\n",
    "        x = x.permute(0,3,1,2)\n",
    "        reshape_size = channel*freq\n",
    "        x = x.reshape(batch_size, timesteps, -1)\n",
    "        h0 = Variable(torch.zeros(2, x.size(0), 32).requires_grad_())\n",
    "        if self.use_cuda:\n",
    "            h0 = h0.cuda()\n",
    "        out, (hn) = self.rnn(x, (h0.detach()))\n",
    "        out = self.linear(out[:, -1, :])  \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: \n",
    "##### **Resnet** is one of the famous models used in computer vision tasks which has more than 100 layers. Acknowledging the performance of ResNet in computer vision application we have decided to use ResNet and its variants for artists classification on **Mel-spectrogram images**. Resnet uses **residual connections** for deep networks in order to solve **diminishing gradient problems**. In a typical Resnet model, those residual connections skip approximately 3-4 layers. For the task of classifying Mel-spectrogram image based on artists we have used the following variants of ResNet :\n",
    " *  **Variant 1 : ResNet50**\n",
    " * **Variant 2 :3 layers of ResNet50 + 2 Layers of GRU**:- in order to detect time-based feature in the time vs Mel image we have added 2 Layers of GRU network at the end of 3 layers (each layer in ResNet50 is comprised of multiple Conv nets) of ResNet50 model. This model was the best performing model from all the models we tried implementing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "reference code Programmed by Aladdin Persson <aladdin.persson@hotmail.com>\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class block(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n",
    "    ):\n",
    "        super(block, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            intermediate_channels,\n",
    "            intermediate_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            intermediate_channels,\n",
    "            intermediate_channels * self.expansion,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
    "        self.relu = nn.ELU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, image_channels, num_classes, use_cuda):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ELU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Essentially the entire ResNet architecture are in these 4 lines below\n",
    "        self.layer1 = self._make_layer(\n",
    "            block, layers[0], intermediate_channels=64, stride=1\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block, layers[1], intermediate_channels=128, stride=2\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block, layers[2], intermediate_channels=256, stride=2\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block, layers[3], intermediate_channels=512, stride=2\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "        \n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=8192, \n",
    "            hidden_size=32, \n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.2)\n",
    "        self.linear = nn.Linear(32,num_classes)\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "         # input format is (B,C,F,T) . For RNN we need input form (B,T,C*F) . where channel and frequency \n",
    "        # dimensions are considered as a feature at any given time.\n",
    "        batch_size, channel,freq, timesteps = x.size()\n",
    "        x = x.permute(0,3,1,2)\n",
    "        reshape_size = channel*freq\n",
    "        x = x.reshape(batch_size, timesteps, -1)\n",
    "        h0 = Variable(torch.zeros(2, x.size(0), 32).requires_grad_())\n",
    "        if self.use_cuda:\n",
    "            h0 = h0.cuda()\n",
    "        out, (hn) = self.rnn(x, (h0.detach()))\n",
    "        out = self.linear(out[:, -1, :])\n",
    "        return out\n",
    "        \n",
    "       \n",
    "\n",
    "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
    "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
    "        # to the layer that's ahead\n",
    "        if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.in_channels,\n",
    "                    intermediate_channels * 4,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                ),\n",
    "                nn.BatchNorm2d(intermediate_channels * 4),\n",
    "            )\n",
    "\n",
    "        layers.append(\n",
    "            block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
    "        )\n",
    "\n",
    "        # The expansion size is always 4 for ResNet 50,101,152\n",
    "        self.in_channels = intermediate_channels * 4\n",
    "\n",
    "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
    "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
    "        # and also same amount of channels.\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, intermediate_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def MusicArtistClassificationModel_ResNet50(use_cuda,img_channel=3, num_classes=1000):\n",
    "    return ResNet(block, [3, 4, 6, 3], img_channel, num_classes, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring paths\n",
    "data_path = \"../input/mp3s32k/mp3s-32k\"\n",
    "dataset_path = \"../input/song-dataset/song_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfroming the mp3 file to spectrograms\n",
    "transform(data_path,dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#Loading Dataset based on song/album \n",
    "#Old code\n",
    "'''\n",
    "#X_train, y_train, _ , X_val, y_val, _ , X_test, y_test, _ = load_songs(data_path,dataset_path,0.1,0.1)\n",
    "X_train, y_train, _ , X_val, y_val, _ , X_test, y_test, _ = load_album(data_path,dataset_path)\n",
    "'''\n",
    "\n",
    "#Changed code\n",
    "#X_train, y_train, S_train, X_val, y_val, S_val, X_test, y_test, S_test = load_songs(data_path,dataset_path,0.1,0.1)\n",
    "X_train, y_train, S_train, X_val, y_val, S_val, X_test, y_test, S_test = load_album(data_path,dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slice songs to 1 second sample (31 frames)\n",
    "X_train,y_train,S_train = slice_song(X_train,y_train,S_train, 94)\n",
    "X_val,y_val,S_val = slice_song(X_val,y_val,S_val, 94)\n",
    "X_test,y_test,S_test = slice_song(X_test,y_test,S_test, 94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a spectrogram\n",
    "plot_spectrogram(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding the artists\n",
    "y_train, label, onehot = encode(y_train)\n",
    "y_val, label, onehot = encode(y_val, label, onehot)\n",
    "y_test, label, onehot = encode(y_test, label, onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding an extra dimension\n",
    "X_train = X_train.reshape(X_train.shape + (1,))\n",
    "X_val = X_val.reshape(X_val.shape + (1,))\n",
    "X_test = X_test.reshape(X_test.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating batches for training, validation and testing set  \n",
    "train_dataloader = load_data(X_train, y_train, 32)\n",
    "validation_dataloader = load_data(X_val, y_val, 32)\n",
    "test_dataloader =  load_data(X_test, y_test, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Garbage Collection\n",
    "del X_train, y_train, S_train, X_val, y_val, S_val, X_test, y_test, S_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking hardware\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.cuda.manual_seed(1234)\n",
    "\n",
    "#Initializing models\n",
    "#model = MusicArtistClassificationModel(1,20,use_cuda)\n",
    "model = MusicArtistClassificationModel_ResNet50(1,20, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "train_loss,val_loss,train_f1,val_f1,time,model = train_predict(train_dataloader, validation_dataloader, model, 300, 1e-4, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the time taken by the model in minutes\n",
    "print((time//1000)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot F1 scores in training and validation\n",
    "plot_trn_val_f1(train_f1,val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot loss in training and validation\n",
    "plot_trn_val_loss(train_loss,val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predcitions using testing dataset and final model\n",
    "test_predict(model,validation_dataloader,use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Improving the F1 scores  \n",
    "### 2) Working with more song samples by adjusting the sample length "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
